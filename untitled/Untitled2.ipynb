{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308ce6e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21692\\2834507561.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Setting seeds (Optional)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "# Setting seeds (Optional)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42) \n",
    "\n",
    "NUM_SAMPLES = 1000\n",
    "lr = 0.1\n",
    "mse_loss = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "# Función para crear datos sintéticos\n",
    "def create_dummy_data(num_samples):\n",
    "  x = tf.expand_dims(tf.constant([complex(i/num_samples,i/num_samples) for i \n",
    "                                  in range(num_samples)], tf.complex128), -1)\n",
    "  # f(x): x -> 5x + ruido\n",
    "  y = tf.expand_dims(tf.constant([complex(5*(j/num_samples) + random.random(),\n",
    "                                          5*(j/num_samples) + random.random()) for j \n",
    "                                  in range(num_samples)], tf.complex128), -1)\n",
    "  return x,y\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "def train_complex(train_x, train_y, test_x, test_y, w, epochs):\n",
    "  \n",
    "  for i in range(epochs):\n",
    "    \n",
    "    # 'Revolvemos' los datos\n",
    "    indices = tf.range(start=0, limit=train_x.shape[0], dtype=tf.int32)\n",
    "    shuffled_indices = tf.random.shuffle(indices)\n",
    "    train_x = tf.gather(train_x, shuffled_indices)\n",
    "    train_y = tf.gather(train_y, shuffled_indices)\n",
    "\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "# --------------------Hay que obtener y_pred. Para ello se ocupa la activación lineal para éste ejercicio.\n",
    "      y_pred = tf.matmul(train_x, tf.cast(w, tf.complex128))\n",
    "    \n",
    "# --------------------Obtener la pérdida con la función de pérdida ocupando el valor real y el valor predicho\n",
    "      mse = mse_loss(train_y, y_pred)\n",
    "    \n",
    "# --------------------Imprimir cada diez iteraciones el valor de la función de pérdida\n",
    "# --------------------Tanto para el \n",
    "    if i % 10 == 0:\n",
    "      val_loss = mse_loss(test_y, tf.matmul(test_x, tf.cast(w, tf.complex128)))\n",
    "      print(f\"Training Loss at epoch {i}: {tf.abs(mse).numpy()}, Validation Loss: {tf.abs(val_loss).numpy()}\")\n",
    "\n",
    "\n",
    "# -------------------- Obtener los gradientes ocupando la derivada de Wirtinger\n",
    "    dL_dwbar = tape.gradient(mse, w)\n",
    "\n",
    "\n",
    "# --------------------Aplicar la retropropagación\n",
    "    w.assign(w - dL_dwbar * lr)\n",
    "\n",
    "# --------------------Imprimir alguna leyenda de que el entrenamiento ha terminado\n",
    "  \n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "def train_real(train_x, train_y, val_x, val_y, w_real, w_imag, epochs):\n",
    "\n",
    "  # Dividimos los datos de validación en sus componentes reales e imaginarios\n",
    "  val_x_real, val_x_imag = tf.math.real(val_x), tf.math.imag(val_x)\n",
    "  val_y_real, val_y_imag = tf.math.real(val_y), tf.math.imag(val_y)\n",
    "\n",
    "  for i in range(epochs):\n",
    "\n",
    "    # 'Revolvemos' los datos al inicio de cada época\n",
    "    indices = tf.range(start=0, limit=train_x.shape[0], dtype=tf.int32)\n",
    "    shuffled_indices = tf.random.shuffle(indices)\n",
    "    train_x = tf.gather(train_x, shuffled_indices)\n",
    "    train_y = tf.gather(train_y, shuffled_indices)\n",
    "\n",
    "# -------------------Dividir las partes real e imaginaria de los datos 'revueltos'\n",
    "    x_real, x_imag =  tf.math.real(train_x), tf.math.imag(train_x)\n",
    "    y_real, y_imag =  tf.math.real(train_y), tf.math.imag(train_y)\n",
    "\n",
    "    with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
    "      \n",
    "# ------------------Obtener el valor predicho para cada componente de forma separada\n",
    "      y_pred_real = tf.matmul(x_real, tf.cast(w_real, tf.float64))\n",
    "      y_pred_imag = tf.matmul(x_imag, tf.cast(w_imag, tf.float64))\n",
    "\n",
    "\n",
    "# -------------------Calculamos las pérdidas\n",
    "      mse_real = mse_loss(y_real, y_pred_real)\n",
    "      mse_imag = mse_loss(y_imag, y_pred_imag)\n",
    "# -------------------------------------------    \n",
    "    if i % 10 == 0:\n",
    "      val_pred_y_real = tf.matmul(val_x_real, tf.cast(w_real, tf.float64))\n",
    "      val_pred_y_imag = tf.matmul(val_x_imag, tf.cast(w_imag, tf.float64))\n",
    "      val_loss = mse_loss(val_y_real, val_pred_y_real) + mse_loss(val_y_imag, val_pred_y_imag)\n",
    "      print(f\"Training Loss at epoch {i}: {mse_real.numpy() + mse_imag.numpy()}, Validation Loss: {val_loss.numpy()}\")\n",
    "# --------------------------------Se obtienen las gradientes de forma separada\n",
    "    dL_dw_r = tape1.gradient(mse_real, w_real)\n",
    "    dL_dw_i = tape2.gradient(mse_imag, w_imag)\n",
    "\n",
    "\n",
    "# --------------------------------------Aplicar en ambos componentes la retropropagación\n",
    "    w_real.assign(w_real - dL_dw_r * lr)\n",
    "    w_imag.assign(w_imag - dL_dw_i * lr)\n",
    "\n",
    "\n",
    "  print(\"Training finished\")\n",
    "\n",
    "\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "  # Crear datos ficticios\n",
    "x, y  = create_dummy_data(NUM_SAMPLES)\n",
    "# Crear subconjuntos de entrenamiento y de validación (80%-20%)\n",
    "train_x, test_x, train_y, test_y = x[:int(.8*NUM_SAMPLES), :], x[int(.8*NUM_SAMPLES):, :], y[:int(.8*NUM_SAMPLES),:], y[int(.8*NUM_SAMPLES):,:]\n",
    "\n",
    "# Inicializar los pesos para el entrenamiento\n",
    "w = tf.Variable(tf.zeros((1,1), tf.complex128), tf.complex128)\n",
    "# Ejemplo de optimización en el entrenamiento con variable compleja\n",
    "train_complex(train_x, train_y, test_x, test_y, w, 30)\n",
    "\n",
    "# Inicialización de los pesos para el entrenamiento de forma separada\n",
    "w_real, w_imag = tf.Variable(tf.zeros((1,1), tf.float64)), tf.Variable(tf.zeros((1,1), tf.float64))\n",
    "# Ejemplo de optimización con variable real\n",
    "train_real(train_x, train_y, test_x, test_y, w_real, w_imag)\n",
    "\n",
    "#//////////////////////////////////////////////////////////////////////////////////////////////////\n",
    "\n",
    "# Realizar la graficación del comportamiento de función de pérdida respecto\n",
    "# de cada una de las épocas, esto tanto para lo obtenido para el conjunto de entrenamiento\n",
    "# y lo obtenido para el conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac2c3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
